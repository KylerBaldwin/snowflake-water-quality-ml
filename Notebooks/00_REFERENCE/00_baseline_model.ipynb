{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "id": "4d8e5e58-82ac-467a-bfb8-2d03a43381ad",
      "metadata": {
        "language": "python"
      },
      "source": "import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nfrom xgboost import XGBRegressor",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0fd736ce-5ca1-40dd-a01c-7d381277be22",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "83cedfff-3edc-4967-8fa0-c027754f1326",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "TRAIN_VIEW = \"WATER_QUALITY.FEATURES.TRAINING_FEATURES\" \nVAL_VIEW = \"WATER_QUALITY.FEATURES.VALIDATION_FEATURES\" \nSUBMISSION_TEMPLATE = \"WATER_QUALITY.RAW.SUBMISSION_TEMPLATE\"\nDATE_COL   = \"SAMPLE_DATE\"\nID_COLS    = [\"SAMPLE_DATE\", \"LATITUDE\", \"LONGITUDE\"]\nDROP  = [\"YEAR\", \"MONTH\"]\nTARGETS    = {\n    \"TOTAL_ALKALINITY\": \"total_alkalinity\",\n    \"ELECTRICAL_CONDUCTANCE\": \"electrical_conductance\",\n    \"DISSOLVED_REACTIVE_PHOSPHORUS\": \"dissolved_reactive_phosphorus\"\n}",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f7a22ea9-d586-4959-ab65-0ceaaa7d5179",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "df = session.table(TRAIN_VIEW).to_pandas()\nho_df = session.table(VAL_VIEW).to_pandas()\nsubmission_df = session.table(SUBMISSION_TEMPLATE).to_pandas()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "66cdb6dd-5296-4531-8eaf-033369c75ea2",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "df.shape",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b316f245-2534-4e02-bb1a-7e5a8fe524c6",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "df = df.dropna()\ndf.shape",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "980f71c1-6fc5-43f6-9cd3-9a07f2aac85c",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "def spatial_temporal_train_val_split(\n    df: pd.DataFrame,\n    date_col: str,\n    lat_col: str,\n    lon_col: str,\n    spatial_holdout_frac: float = 0.2,\n    time_train_frac: float = 0.8,\n    cell_km: float = 25,\n    seed: int = 42\n):\n    df = df.copy()\n    df[date_col] = pd.to_datetime(df[date_col])\n\n    # ---- Spatial blocks --------------------------------------\n    lat = df[lat_col].astype(float).to_numpy()\n    lon = df[lon_col].astype(float).to_numpy()\n\n    deg_lat = cell_km / 111.0\n    mean_lat_rad = np.deg2rad(np.nanmean(lat))\n    deg_lon = cell_km / (111.0 * np.cos(mean_lat_rad) + 1e-12)\n\n    lat_bin = np.floor(lat / deg_lat).astype(int)\n    lon_bin = np.floor(lon / deg_lon).astype(int)\n\n    df[\"spatial_block\"] = list(zip(lat_bin, lon_bin))\n\n    # ---- Spatial holdout -------------------------------------\n    rng = np.random.default_rng(seed)\n    blocks = df[\"spatial_block\"].unique()\n    n_holdout = max(1, int(len(blocks) * spatial_holdout_frac))\n    holdout_blocks = set(rng.choice(blocks, size=n_holdout, replace=False))\n\n    seen = df[~df[\"spatial_block\"].isin(holdout_blocks)].copy()\n\n    # ---- Time-aware split on seen blocks ---------------------\n    seen = seen.sort_values(date_col)\n    cut = int(len(seen) * time_train_frac)\n\n    train = seen.iloc[:cut].copy().drop(columns=['spatial_block'])\n    val   = seen.iloc[cut:].copy().drop(columns=['spatial_block'])\n    \n    print(f\"train shape: {train.shape}\")\n    print(f\"\\n val shape: {val.shape}\")\n    \n    return train, val",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "22cf2bec-c67f-4fdf-bf80-0492503a2874",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Normalize column names\ndf.columns = [c.lower() for c in df.columns]\nho_df.columns = [c.lower() for c in ho_df.columns]\nsubmission_df.columns = [c.lower() for c in submission_df.columns]\n\ndate_col = DATE_COL.lower()\n\n# Sort by time, do time-aware split (80/20)\ndf = df.sort_values(date_col)\ntrain_df, val_df = train_test_split(df, test_size=0.3, random_state=42)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "92733a22-cb6a-4182-96b3-d3c33e530e20",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "train_df.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e73d9e26-1dea-4298-a344-a5847c520509",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Identify feature columns"
    },
    {
      "id": "0aa6796b-2f12-45a6-9f56-1a4394e69321",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "target_cols = [v for v in TARGETS.values()]\ndrop_cols = set([c.lower() for c in ID_COLS] + target_cols + DROP)\n\nfeature_cols = [c for c in df.columns if c not in drop_cols]",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8239e9bf-4dd0-427f-a92f-5817056fb667",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Separate numeric vs categorical"
    },
    {
      "id": "2bb45e7b-496a-4666-871d-6f253cc30693",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "numeric_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(df[c])]\ncategorical_cols = [c for c in feature_cols if pd.api.types.is_object_dtype(df[c])]",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e315b7ad-d6a0-430c-8c4a-676fd92f6de7",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "# Preprocess"
    },
    {
      "id": "36e3ad1e-5db3-4df3-be97-81d604524102",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "numeric_pipe = Pipeline(steps=[\n    (\"imputer\", SimpleImputer()),\n    (\"scaler\", StandardScaler())\n])\n\ncategorical_pipe = Pipeline(steps=[\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npre = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_pipe, numeric_cols),\n        (\"cat\", categorical_pipe, categorical_cols)\n    ],\n    remainder=\"drop\"\n)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fb0e4638-13c1-4fd7-9211-560cbb73c412",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "def train_one_target(y_col: str):\n    # Drop rows where this target is null\n    tr = train_df[train_df[y_col].notna()].copy()\n    va = val_df[val_df[y_col].notna()].copy()\n\n    X_train, y_train = tr[feature_cols], tr[y_col]\n    X_val, y_val     = va[feature_cols], va[y_col]\n\n    y_train = np.log1p(y_train.values)\n    y_val = np.log1p(y_val.values)\n\n    model = Ridge(alpha=1.0, random_state=42)\n\n    pipe = Pipeline(steps=[\n        (\"preprocess\", pre),\n        (\"model\", model)\n    ])\n\n    pipe.fit(X_train, y_train)\n    pred = pipe.predict(X_val)\n\n    mae = mean_absolute_error(y_val, pred)\n    mse  = mean_squared_error(y_val, pred)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(y_val, pred)\n\n    return pipe, {\"mae\": mae, \"rmse\": rmse, \"r2\": r2, \"n_val\": len(y_val)}",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6505f402-90f5-4a63-9794-3c66dee48fb8",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "models = {}\nmetrics = {}\n\nfor label, col in TARGETS.items():\n    m, met = train_one_target(col)\n    models[label] = m\n    metrics[label] = met\n\nmetrics",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f69d1dc9-4a11-48ab-974e-60413aef0aba",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "pipe = models[\"TOTAL_ALKALINITY\"]\nridge = pipe.named_steps[\"model\"]\n\ncoef = ridge.coef_\nintercept = ridge.intercept_\n\nfeature_names = pipe.named_steps[\"preprocess\"].get_feature_names_out()\n\ncoef_df = pd.DataFrame({\n    \"feature\": feature_names,\n    \"coefficient\": coef\n}).sort_values(\"coefficient\", key=abs, ascending=False)\n\ncoef_df.head(20)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ed507dae-8b09-4dbd-94bc-9a2f07685641",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "preds = {}\n\nfor target in target_cols:\n    pipe = models[target.upper()]\n    pred = pipe.predict(ho_df[feature_cols])\n    preds[target] = np.clip(np.expm1(pred), 0, None)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7bf2d273-23da-45d9-8ff3-b1d84721a13d",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "#ids = [\"sample_date\", \"latitude\", \"longitude\"]\n\n#pred_df = ho_df[ids].copy()\n#for target in target_cols:\n    #pred_df[target] = preds[target]\n\n#submission_df = submission_df.drop(columns=target_cols, errors=\"ignore\").merge(pred_df, on=ids, how=\"left\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f1fa011a-6a87-40f7-85d6-327134ebd88c",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "#submission_df.columns = sub_cols\n#submission_df.head(submission_df.shape[0])",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7c72da5a-a1d3-4de6-be13-7a2dfe1a8267",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "def fit_xgb_per_target(train_df, val_df, feature_cols, target_cols, seed=42):\n    fitted = {}\n    val_preds = {}\n    metrics = []\n\n    X_tr = train_df[feature_cols]\n    X_va = val_df[feature_cols]\n\n    for t in target_cols:\n        y_tr = train_df[t].values\n        y_val = val_df[t].values\n\n        # Safety: enforce non-negativity for transform (if you have tiny negatives from noise)\n        y_tr = np.clip(y_tr, 0, None)\n        y_tr_t = np.log1p(y_tr)\n\n        model = XGBRegressor(\n            n_estimators=3000,\n            learning_rate=0.03,\n            max_depth=6,\n            min_child_weight=5,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            reg_alpha=0.0,\n            reg_lambda=1.0,\n            gamma=0.0,\n            objective=\"reg:squarederror\",\n            tree_method=\"hist\",\n            random_state=seed,\n            n_jobs=-1,\n            early_stopping_rounds=100\n        )\n\n        model.fit(\n            X_tr, y_tr_t,\n            eval_set=[(X_va, np.log1p(np.clip(val_df[t].values, 0, None)))],\n            verbose=False\n        )\n\n        # Predict on val in transformed space then invert\n        p_va_t = model.predict(X_va)\n        p_va = np.expm1(p_va_t)\n        p_va = np.clip(p_va, 0, None)\n\n        fitted[t] = model\n        val_preds[t] = p_va\n\n        # Quick metrics in original space\n        y_va = np.clip(val_df[t].values, 0, None)\n        mae = mean_absolute_error(y_va, p_va)\n        mse  = mean_squared_error(y_va, p_va)\n        rmse = np.sqrt(mse)\n        r2 = r2_score(y_val, p_va)\n\n        metrics.append({\"target\": t, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"best_ntree\": model.best_iteration})\n\n    metrics_df = pd.DataFrame(metrics).sort_values(\"RMSE\")\n    return fitted, val_preds, metrics_df",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9f88bd4c-8209-401a-a9db-f0553e67671f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "fitted_models, val_preds, metrics_df = fit_xgb_per_target(\n    train_df, val_df, feature_cols, target_cols, seed=42\n)\n\nmetrics_df",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3f3fbfd8-0a93-437e-bd8b-81ce5a4040d2",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "preds = {}\n\nfor target in target_cols:\n    pipe = fitted_models[target]\n    pred = pipe.predict(ho_df[feature_cols])\n    preds[target] = np.clip(np.expm1(pred), 0, None)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cc9f0fe1-ac04-4030-b9fc-4c831831cb80",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "ids = [\"sample_date\", \"latitude\", \"longitude\"]\n\npred_df = ho_df[ids].copy()\nfor target in target_cols:\n    pred_df[target] = preds[target]\n\nsubmission_df = submission_df.drop(columns=target_cols, errors=\"ignore\").merge(pred_df, on=ids, how=\"left\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6b4a10dc-d1b0-4c2b-869d-f9bd1edd5665",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "submission_df.head(submission_df.shape[0])",
      "outputs": [],
      "execution_count": null
    }
  ]
}